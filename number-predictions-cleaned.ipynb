{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da9f80ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.datasets import EMNIST\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import xgboost\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from skimage.morphology import erosion, dilation, opening, closing\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "from skimage.morphology import remove_small_objects \n",
    "from skimage.morphology import (disk, square, diamond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "554405a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data/df.pkl')\n",
    "final_df = pd.read_csv('data/final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bf3f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c0e9bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load('data/model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af8acef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_map = {'0':0, '1':1, '2':2, '3':3, '4':4, '5':5, '6':6, '7':7, '8':8, '9':9, 'J':10, 'K':11, 'Q':12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34c54fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/91 [00:00<?, ?it/s]/home/nabegh/Anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "100%|██████████| 91/91 [00:00<00:00, 97.75it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(91)):\n",
    "\n",
    "        data_row = df.iloc[i]\n",
    "        truth_row = final_df.iloc[i]\n",
    "        cards = ['P1_number', 'P2_number', 'P3_number', 'P4_number']\n",
    "        \n",
    "        for idx in cards:\n",
    "            vector = cv.resize(data_row[idx], (28, 28))\n",
    "            card = torch.tensor(vector, dtype=torch.float).unsqueeze(0).unsqueeze(0)\n",
    "            truth = truth_row[idx]    \n",
    "            out = model(card)\n",
    "            X.append(out.numpy().reshape(-1))\n",
    "            y.append(classes_map[truth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18d329aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_area(chain):\n",
    "    area = 0\n",
    "    x = 0\n",
    "    y = 0\n",
    "    x_coord = [None]*len(chain)\n",
    "    y_coord = [None]*len(chain)\n",
    "    \n",
    "    for i in range(len(chain)): # Transforming the chain code into x and y coordinates to compute the area\n",
    "        if chain[i] == 0:\n",
    "            x -= 1\n",
    "            y += 1\n",
    "        elif chain[i] == 1:\n",
    "            y += 1\n",
    "        elif chain[i] == 2:\n",
    "            x += 1\n",
    "            y += 1\n",
    "        elif chain[i] == 3:\n",
    "            x += 1\n",
    "        elif chain[i] == 4:\n",
    "            x += 1\n",
    "            y -= 1\n",
    "        elif chain[i] == 5:\n",
    "            y -= 1\n",
    "        elif chain[i] == 6:\n",
    "            x -= 1\n",
    "            y -= 1\n",
    "        elif chain[i] == 7:\n",
    "            x -= 1\n",
    "        else:\n",
    "            x = 1000 # Big value to clearly indicate if an error occurs\n",
    "            y = 1000\n",
    "        x_coord[i] = x\n",
    "        y_coord[i] = y\n",
    "        \n",
    "    a = 0    \n",
    "    for j in range(len(chain)-1): # Calculation of area contributed by consecutive pixels.\n",
    "        a += x_coord[j]*y_coord[j+1] - x_coord[j+1]*y_coord[j]\n",
    "    a += x_coord[len(chain)-1]*y_coord[0] - x_coord[0]*y_coord[len(chain)-1]\n",
    "    \n",
    "    area = abs(a)/2\n",
    "    \n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20439ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chain_code(image):\n",
    "    feat_vect1 = []\n",
    "    feat_vect2 = []\n",
    "    feat_vect3 = []\n",
    "    feat_vect4 = []\n",
    "    chain_area = 0\n",
    "    # Erosion to get rid of small smudges off to the sides.\n",
    "    erosion_number = erosion(image, selem=square(1), out=None)>0\n",
    "    # Clean the images by removing image regions that are smaller than 30 pixels\n",
    "    cleaned_number = remove_small_objects(erosion_number, min_size=30, connectivity=1, in_place=False)\n",
    "    # Dilate the image around a square with side 1\n",
    "    dilation_number = dilation(cleaned_number, selem=square(1), out=None)\n",
    "\n",
    "    img = 255*dilation_number # Dilation step returns True/False values: have to change it back to 0 to 255\n",
    "    \n",
    "    start_point = (0,0)\n",
    "    ## Discover the first point \n",
    "    for i, row in enumerate(img):\n",
    "        for j, value in enumerate(row):\n",
    "            if value == 255:\n",
    "                start_point = (i, j)\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "\n",
    "    directions = [ 0,  1,  2,\n",
    "                   7,      3,\n",
    "                   6,  5,  4]\n",
    "    dir2idx = dict(zip(directions, range(len(directions))))\n",
    "\n",
    "    change_j =   [-1,  0,  1, # x or columns\n",
    "                  -1,      1,\n",
    "                  -1,  0,  1]\n",
    "\n",
    "    change_i =   [-1, -1, -1, # y or rows\n",
    "                   0,      0,\n",
    "                   1,  1,  1]\n",
    "\n",
    "    border = []\n",
    "    chain = []\n",
    "    curr_point = start_point\n",
    "    for direction in directions:\n",
    "        idx = dir2idx[direction]\n",
    "        new_point = (start_point[0]+change_i[idx], start_point[1]+change_j[idx])\n",
    "        if img[new_point] != 0:\n",
    "            border.append(new_point)\n",
    "            chain.append(direction)\n",
    "            curr_point = new_point\n",
    "            break\n",
    "\n",
    "    count = 0\n",
    "    while curr_point != start_point:\n",
    "        #figure direction to start search\n",
    "        b_direction = (direction + 5) % 8 \n",
    "        dirs_1 = range(b_direction, 8)\n",
    "        dirs_2 = range(0, b_direction)\n",
    "        dirs = []\n",
    "        dirs.extend(dirs_1)\n",
    "        dirs.extend(dirs_2)\n",
    "        for direction in dirs:\n",
    "            idx = dir2idx[direction]\n",
    "            new_point = (curr_point[0]+change_i[idx], curr_point[1]+change_j[idx])\n",
    "            if img[new_point] != 0: # if is ROI\n",
    "                border.append(new_point)\n",
    "                chain.append(direction)\n",
    "                curr_point = new_point\n",
    "                break\n",
    "        if count == 15000: break\n",
    "        count += 1\n",
    "\n",
    "    chain_area = calculate_area(chain)\n",
    "    \n",
    "    d0=0\n",
    "    d1=0\n",
    "    d2=0\n",
    "    d3=0\n",
    "    d4=0\n",
    "    d5=0\n",
    "    d6=0\n",
    "    d7=0\n",
    "    \n",
    "    for m in range(len(chain)): # Determines quantity of each direction\n",
    "        if chain[m] == 0:\n",
    "            d0 += 1\n",
    "        elif chain[m] == 1:\n",
    "            d1 += 1\n",
    "        elif chain[m] == 2:\n",
    "            d2 += 1\n",
    "        elif chain[m] == 3:\n",
    "            d3 += 1\n",
    "        elif chain[m] == 4:\n",
    "            d4 += 1\n",
    "        elif chain[m] == 5:\n",
    "            d5 += 1\n",
    "        elif chain[m] == 6:\n",
    "            d6 += 1\n",
    "        elif chain[m] == 7:\n",
    "            d7 += 1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    directions_count = [d0,d1,d2,d3,d4,d5,d6,d7]\n",
    "    \n",
    "    # The deviation gives a quantity to how much the contours makes turns, i.e. a contour with a lot of curves\n",
    "    # will have a big number, and contours like the number 1, will have smaller numbers.\n",
    "    deviation = 0\n",
    "    for i in range(len(chain)-1):\n",
    "        deviation = deviation + abs(chain[i]-chain[i+1])\n",
    "      \n",
    "    return count, border, directions_count, chain_area, deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c1f2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_chain = []\n",
    "y_chain = []\n",
    "for i in range(91):\n",
    "    \n",
    "    data_row = df.iloc[i]\n",
    "    truth_row = final_df.iloc[i]\n",
    "    cards = ['P1_number', 'P2_number', 'P3_number', 'P4_number']\n",
    "    \n",
    "    for index in cards:\n",
    "        img = data_row[index]\n",
    "        img = np.pad(img, ((1, 1), (1, 1)), 'constant', constant_values=((0, 0), (0, 0)))\n",
    "        truth = truth_row[index]\n",
    "        _, _, directions_count, area, indiv_deviation = get_chain_code(img)\n",
    "        code_features = directions_count + [area] + [indiv_deviation]\n",
    "        X_chain.append(code_features)\n",
    "        y_chain.append(classes_map[truth])\n",
    "            \n",
    "        \n",
    "X_chain = np.array(X_chain)\n",
    "y_chain = np.array(y_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1fb407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_both = np.concatenate((X, X_chain), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "547bf69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nabegh/Anaconda3/envs/kaggle/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:47:49] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nabegh/Anaconda3/envs/kaggle/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:47:50] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nabegh/Anaconda3/envs/kaggle/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:47:51] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nabegh/Anaconda3/envs/kaggle/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:47:52] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nabegh/Anaconda3/envs/kaggle/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:47:53] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 89.84% (4.12%)\n"
     ]
    }
   ],
   "source": [
    "model = xgboost.XGBClassifier()\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "results = cross_val_score(model, X_both, y_chain, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db656fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
